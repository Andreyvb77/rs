 # **Итоговый проект: разработка гибридной системы рекомендаций книг с нейросетевыми моделями** #

**Итоговый проект: разработка гибридной системы рекомендаций книг с нейросетевыми моделями**

### **Данные:** ###
Для обучения моделей использован датасет Goodreads-10k, включающий:

- `ratings.csv` - оценки пользователей книгам
- `books.csv `- метаданные о книгах
- `tags.csv и book_tags.csv `- теги книг для контентной части рекомендаций

### **Архитектура системы** ### 
**Базовые модели**
В рамках проекта реализованы и протестированы четыре базовых подхода:

1. `Popularity Model` - рекомендации на основе популярности книг
2. `Content-Based Model `- рекомендации на основе схожести книг через TF-IDF векторизацию названий и тегов
3. `Item-Based Collaborative Filtering` - рекомендации на основе схожести книг, оцененных пользователями
4. `SVD (Matrix Factorization)` - матричная факторизация для выявления скрытых факторов предпочтений

### **Гибридная система** ###
Гибридный подход объединяет все модели через взвешенное усреднение их предсказаний
```
def _normalize_scores(self, scores_dict, model_weight, max_items=100):
    """Выполняет min-max нормализацию скоров с учетом веса модели"""
    ...
    
def _get_model_recommendations_with_scores(self, user_id, n_candidates=50):
    """Получает рекомендации от всех активных моделей и нормализует их скоры"""
    ...
    
def get_recommendations(self, user_id, n_recommendations=10):
    """Основной метод, возвращающий топ-N рекомендаций для пользователя"""
    ...
```
### **Расширенные признаки** ### 

**Признаки пользователей:**
- Средний рейтинг `(user_avg_rating)`
- Количество оценок `(user_rating_count)`
- Стандартное отклонение оценок `(user_rating_std)`
- Категоризация активности `(user_activity_level: inactive, low, medium, active)`

**Признаки книг:**

- Средний рейтинг `(book_avg_rating)`
- Количество оценок `(book_rating_count)`
- Стандартное отклонение оценок `(book_rating_std)`
- Категоризация популярности `(popularity_category: low, medium, high)`

**Признаки взаимодействий:**

- Отклонение оценки от среднего пользователя `(rating_deviation_from_user_avg)`
- Схожесть тегов книг с историей пользователя

### **Стратегия разделения данных** ###

**Для корректной оценки качества используется хронологическое разбиение данных по пользователям:**

1. 80% оценок каждого пользователя → train
2. 20% оценок каждого пользователя → test
3. Из трейна дополнительно выделяется валидационная выборка (80/20) для подбора весов гибридной модели

Этот подход имитирует реальное поведение системы и избегает утечки данных.

### **Метрики качества** ###

**Оценка моделей проводится по трем ключевым метрикам:**

- Precision@K - доля релевантных книг среди топ-K рекомендаций
- Recall@K - доля найденных релевантных книг из всех релевантных
- nDCG@K - нормализованный Discounted Cumulative Gain, учитывает порядок и релевантность

### **Автоматическая оптимизация весов** ###

Для гибридной модели реализован автоматический подбор оптимальных весов на валидационной выборке с использованием оптимизации L-BFGS-B

### **Результаты оценки** ### 
<img width="450" height="173" alt="Image" src="https://github.com/user-attachments/assets/92452c70-3950-4961-a6d4-8726144b4ff0" />

### **Выводы:** ### 

1. Контентная модель показала наилучшие результаты среди всех базовых подходов благодаря эффективному использованию тегов и текстового контента книг.
2. Гибридная система продемонстрировала умеренные, но стабильные результаты, превосходящие большинство базовых подходов по ключевым метрикам:

  - Гибридная система успешно идентифицирует релевантные книги, особенно при увеличении глубины рекомендаций (Recall@10 выше, чем Recall@5).
  - nDCG@10 = 0.0040 — лучший результат среди базовых моделей, что говорит о более корректном ранжировании: релевантные книги чаще попадают в начало списка.

3. Advanced Hybrid (с нейросетевой Two-Tower моделью) показал лучшие результаты при k=10, что свидетельствует о его способности находить более разнообразные и релевантные рекомендации для пользователей.
4. Проблема холодного старта для новых пользователей частично решена через fallback-механизмы (использование популярных книг и контентных признаков).

### **Рекомендации для  улучшения** ### 

1. Добавление более сложной нейросетевой архитектуры Wide & Deep для улучшения качества рекомендаций.
2. Расширение тегов книг с помощью эмбеддингов (Sentence-BERT) вместо TF-IDF.
3. Учет контекстных признаков (время суток, день недели).
4. Применение продвинутых методов балансировки популярных и нишевых книг.
5. Увеличение размера валидационной выборки для более стабильной оптимизации весов.
